########################
# Operation manual
########################

# How to create new ETL data load?
1. You need to define Datasets and Pipelines in \config folder in pipelines and datasets .xlsx file 
2. Typeid 1 is SQL, 2 Blobfile, 3 Blobfolder
3. Install new interafaces (dst, src, pip, trg) with install 
4. Create and edit data_model_mapping (sources) 
5. Copy it as .xlsx or .csv 
6. Make sure Firewall settings are ok! = 
run_import
 
# How to create new rdv tables?
1. Execute stored procedure "master_generate_rdv"

# How to drop an existing table(s)?
1. Execute sp "master_dropper_rdv"
	
# How jobs are constructed?
1. Jobs are defined is table "wht_jobs" with log table "wht_jobs_log". 
2. Each job is divided into steps, defined in the "wht_steps" table and log in "wht_job_step_log".
3. Each step is a sp. It has to have a structure like "[sp_list_job_control]".
4. Each step should be entered into the wht_steps table, otherwise no logging occurs.
5. There should be unique "job & step" entry. If a step should be repeated, then put into another job.

# How to create new 

# How to define a new job?

# How to run complete job?

# How to run a job step?

# How to activate/deactivate job?